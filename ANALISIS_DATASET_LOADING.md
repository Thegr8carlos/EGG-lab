# AnÃ¡lisis: Dataset Loading (Carga de Datos)

## âŒ Problema Actual: HARDCODEADO para Inner Speech

### CÃ³digo problemÃ¡tico (`dataset.py`)

**LÃ­nea 22-23**: Labels hardcodeados
```python
LABELS = {31: "arriba", 32: "abajo", 33: "derecha", 34: "izquierda"}
CUE_IDS = set(LABELS.keys())
```

**LÃ­nea 26-45**: FunciÃ³n `_inner_speech_cues()` hardcodeada
```python
def _inner_speech_cues(events):
    for sample, _, eid in events:
        if eid == 15:  # start of run â† HARDCODED
            in_inner_run = False
        elif eid == 22:  # inner speech run â† HARDCODED
            in_inner_run = True
        elif eid == 16:  # end of run â† HARDCODED
            in_inner_run = False
        elif in_inner_run and eid in CUE_IDS:  # â† Solo {31,32,33,34}
            cues.append((int(sample), int(eid)))
```

**LÃ­nea 378**: `upload_dataset()` usa la funciÃ³n hardcodeada
```python
inner_cues = _inner_speech_cues(events)  # Solo funciona con Inner Speech
```

---

## ğŸ”¥ QuÃ© pasa si subes OTRO dataset BDF

**Escenario**: Subes un dataset P300, Motor Imagery, o cualquier otro

**Resultado**:
1. âŒ `_inner_speech_cues()` NO encuentra eventos (busca IDs 15, 22, 16, 31-34)
2. âŒ `inner_cues` = lista vacÃ­a
3. âŒ NO se generan archivos en `Events/`
4. âŒ `Labels/` tiene todo ceros (no hay eventos detectados)
5. âŒ La app NO puede cargar eventos para visualizar
6. âŒ Filtros y transformadas NO funcionan (no hay datos)

---

## ğŸ“‚ Archivos que DEBE generar para que funcione

### Estructura requerida:
```
Aux/{dataset_name}/
â”œâ”€â”€ dataset_metadata.json         â† Metadata global
â””â”€â”€ sub-XX/ses-XX/eeg/
    â”œâ”€â”€ archivo.npy                â† SeÃ±al raw completa (channels Ã— time)
    â”œâ”€â”€ Labels/
    â”‚   â””â”€â”€ archivo.npy            â† Labels por muestra (1 Ã— time)
    â””â”€â”€ Events/
        â”œâ”€â”€ clase1[123.4]{125.6}.npy   â† Evento segmentado
        â”œâ”€â”€ clase2[234.5]{236.7}.npy
        â””â”€â”€ ...
```

### Archivo `dataset_metadata.json`:
```json
{
  "name": "nieto_inner_speech",
  "classes": ["arriba", "abajo", "derecha", "izquierda"],
  "sampling_frequency_hz": 1024.0,
  "channel_names": ["Fp1", "Fp2", "A1", ...],
  "n_events_total": 1280,
  "class_distribution": {
    "arriba": 320,
    "abajo": 320,
    "derecha": 320,
    "izquierda": 320
  }
}
```

---

## âœ… SoluciÃ³n: Hacerlo GenÃ©rico

### Cambios necesarios en `dataset.py`:

**1. Detectar tipo de dataset**
```python
def _detect_dataset_type(events):
    """Detecta si es Inner Speech o genÃ©rico"""
    event_ids = set(events[:, 2])

    # Inner Speech: tiene event IDs 15, 22, 31-34
    if {15, 22, 31, 32, 33, 34}.issubset(event_ids):
        return "inner_speech"

    return "generic"
```

**2. Extraer eventos genÃ©ricos**
```python
def _generic_event_extraction(events, event_id_mapping=None):
    """Extrae TODOS los event IDs Ãºnicos, sin filtrar"""
    # Eliminar espurios
    events = events[events[:, 2] != 65536]

    # Obtener IDs Ãºnicos
    unique_ids = sorted(set(events[:, 2]))

    # Si no hay mapping, crear genÃ©rico
    if not event_id_mapping:
        event_id_mapping = {eid: f"Evento_{eid}" for eid in unique_ids}

    cues = [(int(sample), int(eid)) for sample, _, eid in events if eid in unique_ids]
    return cues, event_id_mapping
```

**3. Modificar `upload_dataset()`**
```python
def upload_dataset(self, path_to_folder, event_id_mapping=None):
    # ...

    for file in files:
        if ext == ".bdf":
            raw_data = self.read_bdf(str(file))
            events = mne.find_events(raw_data, stim_channel="Status")

            # Detectar tipo de dataset
            dataset_type = _detect_dataset_type(events)

            if dataset_type == "inner_speech":
                inner_cues = _inner_speech_cues(events)
                labels_dict = LABELS  # {31: "arriba", ...}
            else:
                inner_cues, labels_dict = _generic_event_extraction(events, event_id_mapping)

            # Resto del cÃ³digo usa inner_cues y labels_dict
```

**4. Agregar UI para configurar mapping**

En `cargar_datos.py`, despuÃ©s de detectar que es genÃ©rico, mostrar modal:
```
Detectado dataset genÃ©rico con Event IDs: [1, 2, 3, 4, 5]

Configura los nombres de clase:
Event ID 1: [Clase_A    ]
Event ID 2: [Clase_B    ]
Event ID 3: [Clase_C    ]
...

[Procesar Dataset]
```

---

## ğŸ¯ ImplementaciÃ³n Paso a Paso (PLAN_MEJORAS.md PASO 4)

Ya estÃ¡ en el plan, pero ahora entiendes el contexto:

### PASO 4.1: DetecciÃ³n de formato
- Agregar `_detect_dataset_type()`
- Detectar Inner Speech vs genÃ©rico

### PASO 4.2: ExtracciÃ³n genÃ©rica
- Agregar `_generic_event_extraction()`
- Usar TODOS los event IDs Ãºnicos

### PASO 4.3: Modificar upload_dataset
- Bifurcar lÃ³gica segÃºn tipo
- Generar archivos correctos para ambos

### PASO 4.4: UI de configuraciÃ³n
- Modal para mapear Event IDs â†’ nombres de clase
- Guardar configuraciÃ³n en JSON

---

## ğŸ“‹ Resumen Ejecutivo

**Actualmente**: Solo funciona con Inner Speech (event IDs hardcodeados)

**Si subes otro BDF**: NO genera Events/, Labels vacÃ­o, app NO funciona

**Archivos necesarios**:
- `archivo.npy` (raw)
- `Labels/archivo.npy` (labels)
- `Events/clase[t1]{t2}.npy` (eventos segmentados)
- `dataset_metadata.json` (metadata)

**SoluciÃ³n**: Detectar tipo, extraer eventos genÃ©ricos, permitir configurar mapping
