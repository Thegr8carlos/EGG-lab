# Gu√≠a de Persistencia de Modelos

## üìÅ Estructura de Directorios

```
src/backend/models/
‚îú‚îÄ‚îÄ p300/              # Modelos para experimentos P300
‚îÇ   ‚îú‚îÄ‚îÄ lstm_20251109_143022.pkl
‚îÇ   ‚îú‚îÄ‚îÄ svm_20251109_143030.pkl
‚îÇ   ‚îî‚îÄ‚îÄ svnn_20251109_143045.pkl
‚îú‚îÄ‚îÄ inner/             # Modelos para Inner Speech
‚îÇ   ‚îú‚îÄ‚îÄ lstm_20251109_144000.pkl
‚îÇ   ‚îî‚îÄ‚îÄ svm_20251109_144100.pkl
‚îî‚îÄ‚îÄ README.md          # Esta gu√≠a
```

## üîÑ Ciclo de Vida del Modelo

### 1Ô∏è‚É£ **Entrenamiento con Auto-Guardado**

```python
from backend.classes.ClasificationModel.LSTM import LSTMNet, LSTMLayer, SequenceEncoder, DenseLayer, ActivationFunction

# Construir arquitectura
lstm_config = LSTMNet(
    encoder=SequenceEncoder(
        input_feature_dim=64,
        layers=[LSTMLayer(hidden_size=128, bidirectional=True)]
    ),
    fc_layers=[DenseLayer(units=64)],
    classification=DenseLayer(units=5, activation=ActivationFunction(kind="softmax"))
)

# Opci√≥n A: train() con auto-guardado (legacy API + persistencia)
metrics = LSTMNet.train(
    lstm_config,
    xTest=["data/test_01.npy"],
    yTest=["data/test_labels_01.npy"],
    xTrain=["data/train_01.npy", "data/train_02.npy"],
    yTrain=["data/train_labels_01.npy", "data/train_labels_02.npy"],
    epochs=50,
    batch_size=32,
    model_label="p300"  # üëà Auto-guarda en: src/backend/models/p300/lstm_TIMESTAMP.pkl
)

# Opci√≥n B: fit() con auto-guardado (nueva API completa)
result = LSTMNet.fit(
    lstm_config,
    xTest=["data/test_01.npy"],
    yTest=["data/test_labels_01.npy"],
    xTrain=["data/train_01.npy"],
    yTrain=["data/train_labels_01.npy"],
    epochs=50,
    batch_size=32,
    model_label="inner"  # üëà Auto-guarda en: src/backend/models/inner/lstm_TIMESTAMP.pkl
)

# Acceder a m√©tricas y modelo
print(f"Accuracy: {result.metrics.accuracy:.3f}")
print(f"Training time: {result.training_seconds:.2f}s")
print(f"Loss curve: {result.history['loss']}")
```

### 2Ô∏è‚É£ **Guardado Manual (Sin Auto-Guardado)**

```python
# Si NO pasas model_label, debes guardar manualmente
result = LSTMNet.fit(lstm_config, xTest, yTest, xTrain, yTrain)

# Opci√≥n A: Ruta generada autom√°ticamente
save_path = LSTMNet._generate_model_path("p300")  # src/backend/models/p300/lstm_TIMESTAMP.pkl
lstm_config.save(save_path)

# Opci√≥n B: Ruta personalizada
lstm_config.save("custom/path/my_lstm_model.pkl")

# Opci√≥n C: Guardar con metadata adicional (recomendado)
experiment_id = "exp_2024_p300_v3"
save_path = f"src/backend/models/p300/{experiment_id}_lstm.pkl"
lstm_config.save(save_path)
```

### 3Ô∏è‚É£ **Carga del Modelo**

```python
# Cargar desde ruta espec√≠fica
lstm_model = LSTMNet.load("src/backend/models/p300/lstm_20251109_143022.pkl")

# ‚úÖ El modelo est√° listo para inferencia inmediatamente
predictions = LSTMNet.query(
    lstm_model,
    sequences=[seq1, seq2, seq3],  # Lista de arrays (T, F)
    return_logits=False
)

# Con probabilidades
preds, probs = LSTMNet.query(lstm_model, sequences, return_logits=True)
```

### 4Ô∏è‚É£ **Gesti√≥n en Streamlit (Session State)**

```python
import streamlit as st
from backend.classes.ClasificationModel.SVM import SVM

# ==================== P√ÅGINA DE ENTRENAMIENTO ====================
st.title("Entrenamiento de Modelo")

# Configurar modelo
svm_config = SVM(kernel="rbf", C=1.0, probability=True)

if st.button("Entrenar y Guardar"):
    # Entrenar con auto-guardado
    result = SVM.fit(
        svm_config,
        xTest=xTest_paths,
        yTest=yTest_paths,
        xTrain=xTrain_paths,
        yTrain=yTrain_paths,
        model_label="p300"  # Auto-guarda
    )
    
    # Guardar instancia en session_state para uso inmediato
    st.session_state['trained_model'] = svm_config
    st.session_state['model_path'] = SVM._generate_model_path("p300")
    
    st.success(f"‚úÖ Modelo entrenado y guardado")
    st.write(f"üìä Accuracy: {result.metrics.accuracy:.3f}")
    st.write(f"üíæ Guardado en: {st.session_state['model_path']}")

# ==================== P√ÅGINA DE INFERENCIA ====================
st.title("Inferencia")

# Opci√≥n 1: Usar modelo de session_state (si est√° en misma sesi√≥n)
if 'trained_model' in st.session_state:
    model = st.session_state['trained_model']
    st.info("üî• Usando modelo de sesi√≥n activa")
else:
    # Opci√≥n 2: Cargar desde disco (nueva sesi√≥n o recarga)
    import glob
    available_models = glob.glob("src/backend/models/p300/*.pkl")
    
    if available_models:
        model_path = st.selectbox("Selecciona modelo guardado", available_models)
        model = SVM.load(model_path)
        st.info(f"üìÇ Modelo cargado desde: {model_path}")
    else:
        st.error("‚ùå No hay modelos guardados. Entrena uno primero.")
        st.stop()

# Realizar inferencia
if st.button("Predecir"):
    predictions = SVM.query(model, x_new_paths)
    st.write(f"Predicciones: {predictions}")
```

### 5Ô∏è‚É£ **Patr√≥n Recomendado: Hybrid (Session + Disco)**

```python
# En m√≥dulo compartido (e.g., src/backend/model_manager.py)
import streamlit as st
from pathlib import Path
import glob

class ModelManager:
    """Gestor centralizado de modelos con fallback autom√°tico."""
    
    @staticmethod
    def get_or_load_model(model_type: str, label: str):
        """
        Intenta obtener modelo de session_state, si no existe carga el m√°s reciente.
        
        Args:
            model_type: "lstm", "svm", "svnn"
            label: "p300", "inner", etc.
        
        Returns:
            Instancia del modelo lista para query()
        """
        key = f"model_{model_type}_{label}"
        
        # 1. Buscar en session_state (r√°pido)
        if key in st.session_state:
            return st.session_state[key]
        
        # 2. Cargar √∫ltimo modelo guardado (fallback)
        pattern = f"src/backend/models/{label}/{model_type}_*.pkl"
        models = sorted(glob.glob(pattern), reverse=True)  # M√°s reciente primero
        
        if models:
            latest = models[0]
            
            # Cargar seg√∫n tipo
            if model_type == "lstm":
                from backend.classes.ClasificationModel.LSTM import LSTMNet
                model = LSTMNet.load(latest)
            elif model_type == "svm":
                from backend.classes.ClasificationModel.SVM import SVM
                model = SVM.load(latest)
            elif model_type == "svnn":
                from backend.classes.ClasificationModel.SVNN import SVNN
                model = SVNN.load(latest)
            
            # Cachear en session_state
            st.session_state[key] = model
            return model
        
        return None
    
    @staticmethod
    def save_and_cache(model, model_type: str, label: str):
        """Guarda a disco Y cachea en session_state."""
        # Generar ruta seg√∫n tipo
        if model_type == "lstm":
            from backend.classes.ClasificationModel.LSTM import LSTMNet
            path = LSTMNet._generate_model_path(label)
        elif model_type == "svm":
            from backend.classes.ClasificationModel.SVM import SVM
            path = SVM._generate_model_path(label)
        elif model_type == "svnn":
            from backend.classes.ClasificationModel.SVNN import SVNN
            path = SVNN._generate_model_path(label)
        
        # Guardar
        model.save(path)
        
        # Cachear
        key = f"model_{model_type}_{label}"
        st.session_state[key] = model
        
        return path

# USO:
from backend.model_manager import ModelManager

# Al entrenar
result = SVM.fit(svm_config, xTest, yTest, xTrain, yTrain)
saved_path = ModelManager.save_and_cache(svm_config, "svm", "p300")
st.success(f"Guardado en: {saved_path}")

# Al inferir (en cualquier p√°gina)
model = ModelManager.get_or_load_model("svm", "p300")
if model:
    predictions = SVM.query(model, new_data)
else:
    st.error("No hay modelo disponible")
```

## üéØ Mejores Pr√°cticas

### ‚úÖ **DO: Usar model_label para experimentos est√°ndar**
```python
# Auto-organiza por tipo de experimento
result = LSTMNet.fit(..., model_label="p300")  # ‚úÖ
result = SVM.fit(..., model_label="inner")     # ‚úÖ
```

### ‚úÖ **DO: Combinar session_state + disco para producci√≥n**
```python
# R√°pido en misma sesi√≥n, persistente entre sesiones
ModelManager.save_and_cache(model, "lstm", "p300")
model = ModelManager.get_or_load_model("lstm", "p300")
```

### ‚úÖ **DO: Usar rutas relativas al proyecto**
```python
# Portabilidad entre m√°quinas
model.save("src/backend/models/p300/final_model.pkl")  # ‚úÖ
```

### ‚ùå **DON'T: Hardcodear rutas absolutas**
```python
# Rompe en otras m√°quinas
model.save("C:/Users/hugus/models/model.pkl")  # ‚ùå
```

### ‚ùå **DON'T: Olvidar manejar ausencia de modelos**
```python
# Puede crashear
model = SVM.load("models/nonexistent.pkl")  # ‚ùå

# Mejor:
try:
    model = SVM.load(path)
except FileNotFoundError:
    st.error("Modelo no encontrado")
```

## üìä Comparaci√≥n de Estrategias

| Estrategia | Velocidad | Persistencia | Complejidad |
|------------|-----------|--------------|-------------|
| **Solo Session State** | ‚ö°‚ö°‚ö° R√°pida | ‚ùå Se pierde al cerrar | üü¢ Baja |
| **Solo Disco** | üê¢ Lenta | ‚úÖ Permanente | üü¢ Baja |
| **Hybrid (Recomendado)** | ‚ö°‚ö° R√°pida | ‚úÖ Permanente | üü° Media |
| **ModelManager** | ‚ö°‚ö° R√°pida | ‚úÖ Permanente | üî¥ Alta |

## üîç Troubleshooting

### Problema: "Modelo no entrenado: usa fit() antes de query()"
**Soluci√≥n**: El modelo cargado no tiene `_tf_model/_svc_model/_keras_model` poblado.
```python
# Verificar antes de query
if hasattr(model, '_svc_model') and model._svc_model is not None:
    predictions = SVM.query(model, data)
else:
    st.error("Modelo no tiene estado entrenado")
```

### Problema: "FileNotFoundError al cargar modelo"
**Soluci√≥n**: Verificar que el archivo existe y la ruta es correcta.
```python
from pathlib import Path

model_path = "src/backend/models/p300/lstm_20251109_143022.pkl"
if Path(model_path).exists():
    model = LSTMNet.load(model_path)
else:
    st.error(f"Archivo no encontrado: {model_path}")
```

### Problema: "pickle.UnpicklingError" o incompatibilidad de versiones
**Soluci√≥n**: Los modelos guardados con pickle dependen de las versiones de librer√≠as.
```python
# Registrar versiones al guardar (en hyperparams)
import tensorflow as tf
import sklearn

result = TrainResult(
    ...,
    hyperparams={
        "tf_version": tf.__version__,
        "sklearn_version": sklearn.__version__,
        ...
    }
)
```

## üìö Ejemplos Completos por Modelo

### LSTM
```python
from backend.classes.ClasificationModel.LSTM import LSTMNet

# Entrenar y auto-guardar
result = LSTMNet.fit(lstm_config, xTest, yTest, xTrain, yTrain, 
                     model_label="p300", epochs=50)

# Cargar y usar
model = LSTMNet.load("src/backend/models/p300/lstm_TIMESTAMP.pkl")
predictions = LSTMNet.query(model, sequences)
```

### SVM
```python
from backend.classes.ClasificationModel.SVM import SVM

# Entrenar y auto-guardar
result = SVM.fit(svm_config, xTest, yTest, xTrain, yTrain, 
                 model_label="inner")

# Cargar y usar
model = SVM.load("src/backend/models/inner/svm_TIMESTAMP.pkl")
predictions = SVM.query(model, x_paths)
```

### SVNN
```python
from backend.classes.ClasificationModel.SVNN import SVNN

# Entrenar y auto-guardar
result = SVNN.fit(svnn_config, xTest, yTest, xTrain, yTrain, 
                  model_label="p300")

# Cargar y usar
model = SVNN.load("src/backend/models/p300/svnn_TIMESTAMP.pkl")
predictions = SVNN.query(model, x_paths)
```

## üöÄ Resumen R√°pido

```python
# 1. ENTRENAR con auto-guardado
result = Model.fit(..., model_label="p300")  # Guarda autom√°ticamente

# 2. USAR inmediatamente (mismo objeto)
predictions = Model.query(model_instance, data)

# 3. CARGAR despu√©s (otra sesi√≥n)
model = Model.load("src/backend/models/p300/model_TIMESTAMP.pkl")
predictions = Model.query(model, data)

# 4. GESTIONAR con ModelManager (producci√≥n)
ModelManager.save_and_cache(model, "svm", "p300")
model = ModelManager.get_or_load_model("svm", "p300")
```
